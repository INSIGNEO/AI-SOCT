

[Solver of Optimization]

	ram = CPU  					#CPU or GPU processes.
	ngpu = 1            				#Number of GPU processors (keras at most 8).
	metrics = log_jaccard 				#Images input shape
	metrics1 = log_dice  				#Images input shape
	metrics2 =  dice				#Images input shape
	batch_size = 16 				#Batch size of train.
	batch_size_test = 16 				#Batch size of test.
	epochs_pre =  16  				#Epochs of pre analysis.
	epochs_roi =  16  				#Epochs of roi analysis.
	epochs_main = 100  				#Epochs of main analysis.
	num_cores =  4 					#Numer of cores.
	store_results =  on				# (on,off) Store in txt all the mean and SD of each image if a big data set does not regomented.
	validation = on				#If the data split with validation data
	validation_split=0.4				#The rate of validation data
	early_stop= False                               #Use the early stop analysis.
	monitor_callbacks= loss                         #Callbacks save metric acc, loss, val_loss, val_acc.
	mode_convert= min       			#Callbacks mode convert max, min, auto.
	gan_synthetic= False 				#Gan synthtetic images.
	crossval_cycle= 1 				#Numerber of cycle of stored weights for Gan model.
	num_synthetic_images= 100 			#Number of synthetic images.
	fft_convert_data=off				#Convert data set to fft image.

[Path]

	store_txt= /../../Initial_Segmentation/Model 					#Path of store models, solvers.
	store_data_test= /../../Initial_Segmentation/Data 					#Path of store models, solvers.
	datapath=  /../../Initial_Segmentation/Data/Input/imageEDED    				#Root of images-labels for segmentation.
	gan_train_directory= /../../Initial_Segmentation/Data/GAN_2017_endo                #Root of Gan synthetic images.


[Data]

	patient_list = use.json 	#dataset .json file the name of patient list
	patient_store_style= use		#Its the way the data of patient's mask and dcm are stored choices: MICCAI_2009, MICCAI_2017, use( mask and dcm in the same path of the specific patient see example in the /Data/ROI path 
	
	#MICCAI_2009_parameters

	label_case_extension_1=-icontour-manual.txt 	#Write the extention of the contour label here i for endo o for epi cardium.
	label_case_extension_2=-ocontour-manual.txt 	#Write the extention of the contour label here i for endo o for epi cardium.
	label_classes= first 				#define the number of classes to simulate both: i, one: only i, two: only o.
	
	#pre dataset

	counter_extention_pre = txt 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_pre  =  dcm 			#Write the extention of image txt, vtk ,jpeg.
	image_shape_pre  =   64 			#images input shape
	original_image_shape_pre  =  256      		#Original shape of images.
	roi_shape_pre  = 32    				#Shape of the ROI image
	pretrain_window = 11    			#Shape of window for the pre-train ROI image
	
	#roi dataset

	counter_extention_roi = jpeg 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_roi  = jpeg 			#Write the extention of image txt, vtk ,jpeg.
	image_shape_roi =  64 				#images input shape
	original_image_shape_roi  = 256			#Original shape of images.
	roi_shape_roi = 32    				#Shape of the ROI image
	
	#main dataset

	counter_extention = jpeg 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention = jpeg 				#Write the extention of image txt, vtk ,jpeg.
	image_shape = 284 				#images input shape
	original_image_shape =  284     		#Original shape of images.
	roi_shape = 196    				#Shape of the ROI image
	restore_image = off    				#Run the main simulation base the stored image in data_extention choice.



[Data Augmentation]

	data_augm =False				#Data augmentation classic, elastic deformation, or noise true or false
	random_apply_in_batch = False 			#Apply random the Data augmentation in each batch true or false.
	data_augm_classic =False				#Data augmentation classic true or false.                       
	rotation_range = 90    			#Rotation range (0-180 degrees).
	width_shift_range = 0.1    			#Width shift range, as a float fraction of the width.
	height_shift_range = 0.1    			#Height shift range, as a float fraction of the height.
	zca_whitening = True 				#Apply ZCA whitening.
	featurewise_center = False 			#Set input mean to 0 over the dataset.
	samplewise_center = True 			#Set each sample mean to 0.
	featurewise_std_normalization = False 		#Divide inputs by std of the dataset.
	samplewise_std_normalization  = True 		#Divide each input by its std.
	horizontal_flip  = True 			#Randomly flip images.
	vertical_flip = True 				#Randomly flip images.
	zoom_range = 0.005   				#Amount of zoom. If a scalar z, zoom in [1-z, 1+z]. Can also pass a pair of floats as the zoom range.
	fill_mode = nearest 				#Points outside boundaries are filled according to mode: constant, nearest, reflect, or wrap.
	alpha = 500    					#Random elastic distortion: magnitude of distortion.
	sigma = 20     					#Random elastic distortion: length scale.
	normalize = True 				#Subtract mean and divide by std dev from each image.
	max_loops = 2                                   #The loop of augmented data that will be created
	shuffle = True					#Shuffle images in each epoch
	noise=False					#Add salt and peper noise to image

[Model net]

	load_weights_roi=                               #Model roi weights to initialize training( /Model dir`).
	load_weights_main= 				#/weights_main__insigneo_da.hdf5 Model main weights to initialize training( /Model dir`).
	loss_weights= 0.5 0.5                        #When using dice or jaccard loss, how much to weight each output class.

	#roi

	roi_model = deep_conv    			#Roi model of analysis.
	roi_activation=relu    				#Kind of activation of net.	
	loss_pre= customized_loss 			#Loss type	
	loss_roi= mean_squared_error 			#Loss type	
	pre_optimizer= adam    				#pre optimizer.
	roi_optimizer= adam    				#roi optimizer.
	roi_learning_rate =				# Depengs the optimization algorithm
	roi_momentum =					# Depengs the optimization algorithm
	roi_decay =					# Depengs the optimization algorithm
	roi_seed =					# Depengs the optimization algorithm

	#main

	main_model = u_net 				#Main model of analysis.
	max_norm_const = off   				#U-net parameter of constarin max norm on, off.
	max_norm_value = 3    				#U-net parameter of constarin max norm value.
	main_activation = relu 				#activation of main of unet.
	loss_main = dice_cross_entropy 		#Loss type.	
	m_optimizer = adam 				#Optimizer: sgd, rmsprop, adagrad, adadelta, adam, adamax, or nadam..	
	height = 284    				#height of unet.
	width = 284 	   				#width of unet.
	classes = 2    					#classes of unet.
	features = 128    				#Input size of features of unet.
	depth = 3    					#Depth of unet.	
	channels = 1    				#channels of unet RGB=3 Grey=1 unet.
	dropout = 0    				#Dropout of unet.
	batchnorm = True   				#Batch normalization of unet.	
	padding = valid     				#Padding of unet.
	learning_rate = 0.1				# Depengs the optimization algorithm
	momentum =					# Depengs the optimization algorithm
	decay =	 					# Depengs the optimization algorithm
	seed =						# Depengs the optimization algorithm


